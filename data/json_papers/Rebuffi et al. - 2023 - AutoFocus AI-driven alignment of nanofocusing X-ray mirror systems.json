{
  "filename": "Rebuffi et al. - 2023 - AutoFocus AI-driven alignment of nanofocusing X-ray mirror systems.pdf",
  "metadata": {
    "title": "AutoFocus: AI-driven alignment of nanofocusing X-ray mirror systems",
    "authors": [
      "Luca Rebuffi",
      "Saugat Kandel",
      "Xianbo Shi",
      "Runyu Zhang",
      "Ross J. Harder",
      "Wonsuk Cha",
      "Matthew J. Highland",
      "Matthew G. Frith",
      "Lahsen Assoufid",
      "Mathew J. Cherukara"
    ],
    "arxiv_id": ""
  },
  "sections": {
    "Abstract": "We describe the application of an AI-driven system to autonomously align and focus complex x-ray mirror systems. The system has been developed and studied on a digital twin of nanofocusing X-ray beamlines, built using advanced optical simulation tools calibrated with wavefront sensing data collected at the beamline. We experimentally demonstrated that the system is systematically capable of positioning a focused beam on the sample, both by simulating the life cycle of the beamline with random perturbations due to typical variations in the light source and optical elements over time, and by conducting similar tests on an actual focusing system.",
    "Introduction": "The fourth-generation synchrotron radiation facility represents a significant advancement in X-ray brightness, offering exciting possibilities for enhanced speed and resolution in X-ray characterization. For example, next-generation synchrotrons will enable nearly atomic-level studies of materials and devices in real-time, unlocking new applications like the analysis of defects in solar materials and batteries and tracking catalytic activity within individual catalyst particles. However, fully realizing this potential necessitates highly focused hard X-ray beams that exhibit minimal wavefront distortion, exceptional stability, and, in some applications, adjustable focal sizes. Among these requirements, preserving the wavefront and coherence of the beam is vital for applications like tomography and coherent X-ray scattering experiments. Wavefront distortions can lead to a deterioration of the sample speckle contrast that hinders data interpretation and may cause phase retrieval methods to fail. To meet these rigorous demands, beamline optical elements must be manufactured to exact specifications, be able to automatically and repeatably align and focus the beam, and provide real-time correction to wavefront deformations. A possible solution to these challenges is the implementation of adaptive optics (AO), a system that functions by dynamically correcting wavefront aberrations using modulating devices, such as deformable mirrors. Successful AO implementation requires high-precision components and sophisticated control systems, such as those needed for a nanofocusing AO mirror system that integrates deformable mirrors, in-situ surface profilers, specialized wavefront sensors, and advanced feedback control systems. The performance of AOs relies on the linearity, dynamics, and repeatability of the optics response to various actuator formats, including mechanical bending, piezoelectric bimorph, and thermal loading. The traditional iterative control method based on linear response models is often slow to converge, taking significant time. We have recently demonstrated the possibility of controlling a new-generation bimorph mirror using machine learning (ML), with a single-shot wavefront sensor based on a coded-mask technique. An NN-based controller was trained with the measured one-dimensional wavefront differential phase and achieved (with a response time of a few seconds) the desired wavefront shapes with sub-wavelength accuracy at 20 keV, a significant improvement compared with the traditional linear model. However, the success of such an ML system relies heavily on the stability and repeatability of the conditions under which the training data are collected. We concluded that the control system could be enhanced by coupling with an auto-alignment system that rapidly responds to beam property changes and restores the initial conditions. Furthermore, an auto-alignment/focusing system can be fundamental for future beamline operations, especially for beamlines with numerous degrees of freedom. Manual alignment and optimization, even when limited to a few degrees of freedom, often fail to achieve an optimal configuration, and stability may be affected by changes in electron beam conditions or environmental fluctuations. Given the complex and demanding nature of the fourth-generation synchrotron beamlines, manual approaches are considered inefficient and, in many cases, nearly impossible. Instead, emerging AI-driven auto-alignment control methods using ML and optimization algorithms are being developed. They aimed to reduce alignment time, allow dynamic adjustments to the coherent focal spot size, and conserve valuable experimental time, marking a promising direction for the next generation of synchrotron radiation facility operations. In this study, advanced and ultra-realistic OASYS simulations of two beamlines at the Advanced Photon Source (APS) of Argonne National Laboratory (ANL) were utilized to demonstrate that Bayesian optimization (BO) with Gaussian processes (GPs) is a robust and efficient approach for auto-aligning X-ray focusing systems. The BO-GP method allowed for an unbiased exploration of large parameter spaces, finding globally optimal solutions even in noisy situations, proved more data-efficient than traditional black-box optimization, and overcame the issues of methods like reinforcement learning that need large data volumes and lack robustness to significant upstream drifts in the beam structure. The approach was developed through the creation of a precise digital twin of the 34-ID-C beamline at the APS, fine-tuned using actual calibration measurements. Virtual alignments were studied on the digital twin before being experimentally tested at the 28-ID-B beamline. The entire control software was integrated into an object-oriented framework allowing dynamic and transparent switching between real and simulated hardware.",
    "Focusing optical systems": "This section describes the two focusing optical systems employed to create and test the automatic AI-driven controller. The 34-ID-C beamline focusing system was first fully characterized to develop an accurate digital twin to study and identify the optimal strategy for AI implementation. We assembled a similar system at the 28-ID-B beamline for experimental validation and comprehensively characterized its digital twin. This allowed us to simulate the experiments, assess potential limitations, identify possible issues, and predict outcomes.\n\n34-ID-C Beamline: The 34-ID beamline at the APS hosts two experimental stations: the Laue diffraction microscopy instrument (34-ID-E) and the Coherent Diffraction Imaging instrument (34-ID-C). The characteristics of the undulator source and the beamline layout can be found in the Supplemental Document, Section S1.1. The monochromator was tuned to an energy of 10 keV using the 3rd harmonic of the undulator. Beamline 34-ID-C uses a pair of bendable Kirkpatrick-Baez (KB) mirrors as the final focusing optics shown in Fig. 1a. A set of slits is employed upstream of the KB mirrors to select the coherent fraction of the monochromatic beam. The typical spot size is ~500 x 500 nm² at the sample position, ~120 mm downstream of the end of the horizontally focusing mirror of the KB pair. A layer of Au nanoparticles (100-200 nm) deposited on a Si substrate is placed at the sample position to determine the focal spot size. The diffraction signal of the 111-family planes of the Au nanoparticle is captured by an area detector and integrated. Motors on the sample holder allow scanning in the transverse plane to provide the horizontal and vertical beam profiles.\n\n28-ID-B Beamline: The 28-ID-B beamline, the Instrumentation Development, Evaluation, & Analysis Beamline (IDEA) at the APS was designed to characterize the performance of state-of-the-art X-ray optics and devices planned for the APS Upgrade (APS-U) project. Additionally, this beamline serves as a testing ground to validate, optimize, and refine new optical concepts and control strategies proposed for APS-U beamlines. The source parameters and beamline layout is reported in the Supplemental Document, Section S1.2. The monochromator was tuned to an energy of 20 keV using the 5th harmonic of the undulator. In experimental hutch B, we assembled a KB mirror focusing system consisting of an outboard-reflecting, horizontally focusing bendable mirror using an in-house flexure bender design and an upward-reflecting PZT (lead zirconate titanate) bimorph mirror manufactured by JTEC Corporation (Osaka, Japan) for vertical focusing. The bender mirror is Pt coated on a silicon substrate, shaped in a trapezoidal form with dimensions measuring 300 mm in length, 36.28 mm at the wide end, 19.32 mm at the narrow end, and 12 mm in thickness. Bending moments are administered to both ends of the mirror through a flexure mechanism, with a piezo linear actuator on each side providing the force. To guarantee bending reproducibility, the positions of the bending arms are continually monitored by two capacitive sensors. The bimorph mirror is Pt coated with an active area of 150 mm (length) x 8 mm (width) on a silicon substrate with a dimension of 160 mm (length) x 50 mm (width) x 10 mm (thickness). Two piezoelectric strips, with 18 separate electrodes on each stripe, are glued on the top surface of the mirror, sandwiching the active area. Each pair of electrodes, at the same position along the strips, forms one actuator capable of modifying the local surface shape, thus forming a total of 18 local surface actuator channels (ch1-ch18). Two long piezo strips are glued to the bottom surface of the mirror, forming a single global bender actuator (ch20) capable of bending the entire optical surface. A grounded channel (ch19) is on the backside of all piezo stripes. In this study, we only utilized the global bender, keeping the surface actuators in a rest position by setting their channel voltages to 500 V. Both mirrors were operated at a grazing angle of 3 mrad. A scintillator-based X-ray detector was placed at the focal plane of the KB mirror, providing 2D images of the transverse profile of the beam. The focal spot was set at ~2.3 m from the vertical mirror center (~3.1 m from the horizontal one), with a typical size of around 10 x 2 µm².",
    "Software driver for the optical systems and their digital twins": "As a simulation engine, we adopted the kernel libraries of OASYS, to create the ultra-realistic digital twin of the two beamlines. The architecture has a command interface consistent across the real hardware drivers and the simulated digital twin. Fig. 3 shows the class diagram of the software for the focusing system of the 34-ID-C beamline, a schematic that was also adapted for the 28-ID-B beamline. The interface (34IDAbstractFocusingOptics) is implemented by both the hardware driver (right side of the diagram) and the digital twins (left side of the diagram, with different implementation corresponding to different simulation strategies). Both the simulated digital twins and the real hardware controller (implemented using EPICS) share a common interface for controlling the motors. From a software engineering perspective, the architecture follows a Facade design pattern that allows one to choose the specific implementation. Fig. 4 displays a portion of the Python code used to instantiate the focusing optics controller. Once the controller instance is obtained—with initial parameters varying between the digital twin and real beamline—it is used by the AI-driven controller without regard for the chosen implementation. The complete code is available in the public online repository. Within the OASYS suite, we used the ray-tracing program ShadowOui to design and prepare the software framework. The source radiation was simulated using the Shadow/SRW hybrid undulator simulator, which generates rays based on the spatial and angular radiation distribution calculated by the wave optics program SRW at a given energy. Then the radiation propagation simulation was carried out using several advanced features: i) The Hybrid method was employed to compute diffraction effects when the beam is clipped by an aperture or mirror length. It can also simulate the effect of figure errors in optical elements when diffraction occurs. ii) The metrology data for all mirrors involved were integrated using the DABAM online metrology database tools. The two-dimensional mesh of the measured surface error profile was added to the surface of each mirror. iii) Analytical models were implemented to generate surface profiles created by the different bender designs at the two beamlines, following the formulas detailed in references. To create a surface profile that closely approximates the ideal shape—such as an elliptical cylinder shape defined by geometrical parameters like source-to-mirror distance (p), mirror-to-focus distance (q), and the grazing angle (theta)—a non-linear least-square fitting process is employed. This process determines the bending forces necessary to match the ideal profile. Subsequently, the bender-induced surface error, representing the discrepancy between the achievable shape through bending and the ideal shape, is incorporated as an additional surface error profile. In addition, we needed to represent the behavior of the bendable mirrors under operating conditions, taking into account that the upstream and downstream bender motors can be activated separately, influencing only a portion of the beam (one-half each if the beam is properly aligned and centered on the mirror surface). To simulate this behavior, we shaped the mirror's upstream half based on the equation corresponding to the upstream motor setup and the downstream half according to the downstream motor setup. These analytical equations, defining the surfaces and corresponding focal positions, are generally related to the force or momentum applied to the mirror, with the focal position typically inversely proportional to the applied force. However, real controllers often operate on different units, such as voltages or distances, depending on the type of motors (e.g., piezometric or stepper motors) that drive the bending mechanism. To reconcile this discrepancy, we calibrated all involved mirrors by measuring the obtained focal position as a function of the motor's setup. The focal position was determined by analyzing the local curvature of the wavefront measured with a coded-mask-based single-shot wavefront sensor. Assuming a linear correlation between force and motor position, we calculated the response function according to (1/q = p0x + p1), where q is the focal position, x is the motor position value (direct position or applied voltage), and p0 and p1 are linear fitting coefficients. By linearly interpolating the corresponding plot (an example shown in Fig. 5), this calibration allowed us to correlate the focal position, and thus the surface profile, with the bender motor positions. Details on the calibration of all the motors can be found in Supplemental Document, Section S2. In the case of the 34-ID-C beamline, it is worth underlining that the simulation of the beam profile at the sample position not only involved the treatment of the mirror surface shape but also included the application of the Hybrid algorithm to account for the diffraction effects from the coherence slits and mirror size. Fig. 6 illustrates the comparison between the measured signal and the simulated one, with identical motor setup, in both at-focus and out-of-focus conditions. All the combined features provided by OASYS lead to an excellent agreement between the simulation and measurements, ensuring that any conclusions drawn from studies on simulated data will be valid and applicable to the real beamline.",
    "AI-driven auto-alignment": "Bayesian optimization (BO) is a model-based optimization method that uses an iterative approach to solve black-box optimization problems with possibly noisy inputs and outputs. BO methods rely on Bayes' theorem to create a statistical \"surrogate\" model that incorporates the previous observations and prior knowledge to decide the next query of the system using a Bayesian interpretation of the statistics. The BO process consists of two primary components: i) a surrogate model that approximates the system response to inputs, updated after each query, and ii) an acquisition function that suggests the next query point based on the surrogate model. For the surrogate model, Gaussian processes (GPs) are a popular choice, providing not only function output but also uncertainty at a query point. A GP is an infinite-dimensional extension to the familiar multivariate normal distribution. Whereas a normal distribution is characterized by its mean and the variance (or the uncertainty) about the mean, a GP is similarly described by a mean function and a covariance kernel. The mean function gives the expected value of the surrogate function at each observation point, while the covariance kernel describes the uncertainty about the model at that point. The GP surrogate model can be expressed as f ~ GP[v(x), k(xi, xj)], where x is the input parameter, v is the mean function, and k is the covariance kernel that encapsulates the joint variability of the possible objective function values for a pair of inputs xi, xj. The mean and covariance functions are chosen in advance to encode prior knowledge about the system under consideration. Commonly, the mean is chosen as a constant function, while the covariance is selected such that points xi, xj that are closer in the input space have a higher positive value. This selection encodes the belief that the function values of nearby points should be closer than those farther apart. Moreover, the covariance kernel encodes assumptions regarding the smoothness and length scale of the objective function. In this work, we employ GPs with a constant mean function and utilize the scaled Matern kernel for the covariance. The acquisition function is typically defined such that its maximum corresponds to a potential optimal point for the objective(s), whether because of large predicted objective values, significant prediction uncertainty, or a combination of both. A popular choice for the acquisition function is the Expected Improvement (EI) function which accounts for both the likelihood that a new query point will improve the objective and the magnitude of the expected improvement. For noise-free observations and a maximization objective, the EI acquisition function takes the form of an integral. This mathematical framework, encompassing the Gaussian process surrogate model and the Expected Improvement acquisition function, provides sufficient machinery for optimizing a typical black-box problem with a single objective.\n\nMulti-objective optimization with Gaussian processes: Beam alignment can be understood and expressed from single-objective and multi-objective perspectives. If the desired beam profile can be accurately described, we can articulate the alignment goal as minimizing a single distance metric between the pixelated test (unaligned) structure and the desired beam structure. Various measures like the Kullback-Leibler (KL) divergence, the Euclidean norm, or the Wasserstein distance (also known as the earth mover's distance) may serve as minimization objectives to capture the difference between the test and desired profiles. However, practical applications reveal weaknesses in these metrics. KL divergence and Euclidean norm are ineffective when there is no overlap (for a large enough misalignment) between the test and target structures, while Wasserstein distance may be computationally prohibitive. Alternately, beam alignment can be viewed as a careful orchestration of multiple priorities, such as the location, shape, and intensity spread of the beam. This perspective requires tuning these factors to desired values while recognizing that optimizing one may compromise others. Although it is possible to assign a priori weights to these priorities to create a single optimization objective, such optimal weighing can be challenging to determine and susceptible to changes in experimental conditions. A more robust approach is identifying a solution for each possible tradeoff between priorities and making a posteriori choice on the desired solution. This full set of solutions forms the \"Pareto front\" (PF) for the multi-objective optimization problem, and a Bayesian approach to map this solution set is known as the Multi-Objective Bayesian Optimization (MOBO) approach. To formalize the multi-objective optimization method, we begin by assuming an optimization problem with the M optimization objectives g(x), where each objective is a maximization objective. A solution g(x*) is considered to dominate another solution g(x') if g(x*) >= g(x') for all m and g(x*) > g(x') for at least one m. Each dominated solution is deemed inferior and undesirable. Conversely, there exist many solutions that do not dominate each other. Then the surface connecting the set of non-dominated solutions is actually an estimate of the true Pareto front. Furthermore, we can use a hypervolume reference point inferior to all the non-dominated solutions to define a hypervolume dominated by (or under) the estimated PF, so that the true PF is the set of points with the maximal dominated hypervolume. This gives us one MOBO approach: an iterative procedure that, at every iteration, identifies a query point that increases the dominated hypervolume, effectively increasing the quality of the estimated PF. In this work, the MOBO surrogate model f is composed of M individual GPs, with each GP a surrogate model for the individual objective g(x). Analogous to the expected improvement (EI) function in the single-objective cases, the Expected Hypervolume Improvement (EHVI) function is a popular acquisition function for the MOBO settings. The EHVI function accounts for both the probability that a new query point will improve the dominated hypervolume and the magnitude of the expected improvement. This work uses the Noisy Expected Hypervolume Improvement (NEHVI) acquisition function that extends EHVI to settings with noisy observations and constraints on any observables in the experiment.\n\nChoice of the optimization objectives: In pursuing the goal of auto-alignment, we need to consider both the position of the beam maximum and the intensity distribution around this maximum. To capture these aspects, we define three optimization objectives related to the full width at half-maximum (FWHM) of the beam, the location of the peak (PL), and the negative logarithm of the peak intensity (NLPI), given by equations relating FWHM_H, FWHM_V, P_H, P_V, and P_int.\n\nMOBO implementation details: We first describe some a priori considerations for the MOBO design. Search space: The search space (or search boundary) for each parameter is determined by experimental considerations (such as the physically viable range for a motor motion) and prior knowledge regarding the parameter's impact on the beam profile. In this work, we use the digital twin and prior calibrations to define physically viable search ranges that should be adequate for the misalignment levels. Although narrowing the search space might lead to faster optimization, we opt not to restrict these overly but to keep them fixed throughout the experiments. Hypervolume reference point: A reference point is provided to specify the lower bound for the optimization objectives, which allows for calculating the sampling hypervolume relative to this reference point, and all the sampled points are expected to improve upon the reference objective value. Although choosing a reference point can significantly impact the sampling, determining the optimal reference point a priori can be challenging. Consequently, we use clearly suboptimal objective values to define the reference points in the subsequent experiments. Constraints: Optionally, equality or inequality constraints can be applied to any observable, such as the integrated intensity. These constraints can filter the sampled points, thereby not only lowering the computational cost per iteration but also guiding the sampling toward more desirable regions. Initialization and termination: A few observations must be acquired in a space-filling manner before initiating the optimization routine. This helps the GPs create useful surrogate models for the full search space, reducing the possibility of the optimization being stuck in a small subset of the search space. We typically use 10 iterations (or trials) of Sobol space-filling sampling on the entire parameter space (unless otherwise stated) for optimization initialization. As for the termination criterion, we simply set a fixed budget for the number of observations and terminate when the budget is expended. Besides the a priori considerations, we must also define a criterion for a posteriori selection of a single beam profile from the multiple candidates comprising the PF estimate. Here, we employ the Nash bargaining solution that dominates the largest number of sampled non-Pareto structures, a simple criterion that does not require prior information about the experiment. However, it is essential to note that selecting a single optimal structure is a challenging research problem. A decision-maker might want to examine the full set of PF optimal structures to make a final choice. The optimization implementation uses custom code that leverages the OASYS API for the beam profile and objective calculation and the Optuna library as the user-facing interface for GP-based optimization and post-processing. For this work, the Optuna library uses the BoTorch library as the backend for GP-based modeling and calculations. Specifically, the multi-objective modeling relies on the BoTorch ModelListGP class, encapsulating individual SingleTaskGP models for each objective function. The default settings for the mean and covariance kernels are as set in the SingleTaskGP model in BoTorch.\n\nDevelopment of the AI-driven controller on 34-ID-C digital twin: We first developed and tested the MOBO autofocusing routine on the focusing optics setup in the 34-ID-C digital twin. In the dual-KB-mirror setup (described in Section 1.1), each mirror is tuned using four motors to adjust the upstream and downstream bending forces, the incident angle (or pitch), and the position (or translation) of the mirror. This results in a total of eight optimization parameters. The collected data consists of 1D vertical and horizontal beam profiles obtained using the diffractometer scan. Given the complexity of defining a single peak intensity value for the data, the optimization was conducted using only the FWHM and PL objectives. For the 34-ID-C numerical experiments, we started with a manually tuned structure obtained using 1e6 source photons and no background (Figs. 8a, 8b, 8d). A random shift was applied to the mirror motors to obtain the initial misaligned structure for the optimization (Figs. 8a, 8b, 8e). The MOBO routine was configured with the objective values of the initial structure as the hypervolume reference point and with a constraint of >=6e3 photons on the integral photon count to ensure that the beam did not drift out of bounds. We started with 10 steps of Sobol sampling followed by 140 steps of the GP-based acquisition and sampling for the full parameter set. The results of the numerical experiment are shown in Fig. 8, with subplots (8a, 8b) displaying the collected data for the reference optimized structure, the initial misaligned structure, and the Nash solution, while subplots (8d-8i) show the 2D beam profiles at the diffractometer position. Note that these 2D profiles were not available and not used for the optimization during a beamline experiment but are provided here for reference and analysis. The results indicate that the MOBO routine produces a highly compact structure comparable to the reference structure. The motor parameter values for the reference, random, and PF structures are listed in Table 1. Differences in such parameter values, between the reference and optimized structures, are consistent with the expected dynamic and behavior of the optical system.\n\nTest of the AI-driven controller on 28-ID-B digital twin: After refining the MOBO routine through the 34-ID-C digital twin experiment, we adapted the procedure for application to the 28-ID-B beamline. Since the data collected in this setting are 2D images, we can define the NLPI objective. We determined using the digital twin that the use of full set of objectives (FWHM, PL, NLPI) is most effective for the beam optimization. We initiated the numerical experiment with 5e4 source photons, excluding background noise. Again, a manually tuned structure was used as a starting point (Fig. 8a [sic - probably 9a]), followed by a random shift to the parameters to obtain the initial misaligned structure (Fig. 8b [sic - probably 9b]). For this experiment, the objective value of the initial structure served as the hypervolume reference. Additionally, a constraint was imposed to maintain the integral photon count at >=1e3 photons, which helped guide the sampling away from the out-of-bounds region. The optimization procedure was launched with 10 steps of Sobol sampling followed by 140 steps of GP-based sampling. The optimization results are illustrated in Fig. 9, with the NS beam structure (Fig. 9c) selected as a posteriori, the remaining PF structures (Figs. 9d-9e), and scatter plots (Figs. 9f-9h) showing the spread and the history of the sampled objective values. The structures in the Pareto front form an envelope in the lower-left region (the desirable region) of the scatter plots, with each structure being an optimal solution based on different tradeoffs among the objectives. The optimal parameter values, the initial settings, and the values associated with the PF structures are compiled in Table 2. A noteworthy observation is that the candidate solution in Fig. 9d contains a long tail in the horizontal direction but has a low FWHM value. This uncovers the limitation of using the FWHM metric: it does not adequately account for non-Gaussian structures with long tails. As a consequence, the NS structure has lower FWHM than the reference structure, but is not as compact and also has a lower peak intensity count.",
    "The AI-driven controller in operating conditions": "After the numerical validation through the digital twin, we tested the auto-alignment procedure in a real-world setting at the 28-ID-B beamline. We conducted two key experiments: i) the alignment of an unfocused structure into a compact, focused structure, and ii) the alignment towards a specific predefined structure.\n\nObtaining a compact, focused structure: To evaluate this fundamental auto-alignment routine, we started from a significantly misaligned structure, as shown in Fig. 10a. Since this was a proof-of-concept exercise conducted in a real, noisy environment, we used looser criteria for the hypervolume reference point, setting them to the suboptimal values of FWHM_HR=40 µm, PL_HR=50 µm, NLPI_HR=infinity, and did not apply any constraints on the integral photon counts. We again performed 10 steps of Sobol sampling across the full parameter space to initialize the MOBO calculation, followed by 100 optimization steps involving all parameters. The experiment was conducted using the same search space as in the numerical experiment with the digital twin. The results shown in Fig. 10 confirm that the MOBO procedure succeeded in producing a compact structure. However, the aberration and background in the experimental data led to the acquisition of structures with a range of FWHM values but similar peak locations and intensities. The PF structures also showed the same trend (see Supplemental Document, Fig. S3). Furthermore, Figs. 10c-10e reveal that the first few optimization iterations were sufficient to discover the central region with favorable candidate structures; the subsequent iterations attempted to find the optimal parameter settings within this favorable region. Detailed descriptions of the candidate PF solutions and the parameter values for the PF solutions can be found in the Supplemental Document, Section S4.\n\nObtaining a structure with specific desired properties: In practical applications, we often desire a structure with a specific shape or level of defocus rather than the most compact focused structure. To emulate this type of alignment challenge, we used the arbitrarily chosen horizontal and vertical FWHM values, FWHM_H,R=18 µm, FWHM_V,R=7 µm respectively, as the reference or desired beam properties. We then modified the FWHM objective in Eq. 6. We used the starting structure shown in Fig. 11a and performed a two-step optimization routine with 10 steps of Sobol and 40 steps of GP-based sampling for translation and pitch parameter subset, followed by 100 sampling steps for the entire parameter set. We note that the efficacy of this two-step method over a one-step optimization for this experimental setup remains undetermined. We used the same hypervolume reference point (excluding the NLPI term) from Section 4.3 for the modified objectives. The results in Fig. 11 show that the MOBO procedure produced a structure with properties close to the reference values.\n\nChallenges and Considerations: Among the optimization objectives we employed, peak location and peak intensity consistently perform well under all scenarios. However, using FWHM as an optimization objective presents challenges, as it does not consider the presence of long tails or other non-Gaussian features in the beam structure. Moreover, defining the precise shape and location of the beam can become difficult in the presence of background interference and noise. A partial solution could be to use more generic measures for the beam width, such as the root mean square (rms) of the beam distribution, for the optimization of non-Gaussian beam profiles, as it happens for highly coherent beams, that have diffraction fringes and/or diffused scattering features/halos around the focused peak. More accurate denoising and beam characterization criteria would be hardware-specific and require careful consideration for each particular experiment setting. A different challenge arises when aiming to align to more complex beam profiles that cannot be simply characterized by the width and peak location. In such cases, we would need to consider one of two approaches: either use a more sophisticated metric like the Wasserstein distance to characterize the structural differences between two beam profiles, or apply numerical inversion techniques or neural network approaches for the precise beam alignment. Specifically for the latter approach, it can still be beneficial to perform a fast and rough alignment using the procedure described in this work before fine-tuning it with another technique. Furthermore, we believe it is feasible to enhance the robustness and efficiency of the proposed auto-alignment approach through further research in several directions. Firstly, careful consideration and potential dynamic tuning of constraints, the hypervolume reference point, and even the search space could significantly improve the efficiency of the auto-alignment routine. Secondly, if the overall goal of the experiment is to maintain a stable optical system through multiple runs of the autofocusing routine, then reusing the information acquired in one auto-alignment run could accelerate future auto-alignments on the same optical system. Alternatively, in a more sophisticated approach, we could exploit the idea of multi-fidelity optimization to create and dynamically update a complex GP-based (or NN-based) model of the optical system, then exploit this extra surrogate for accelerated optimization. Future work might also include designing a reinforcement learning procedure that utilizes the GP-based surrogate model for data-efficient real-time beam stabilization and control. In addition, directly measuring the focal spot using a 2D detector, especially when the spot size is below 100 nm, is exceptionally challenging. Presently, no detector system can provide the necessary spatial resolution for this task. Potential measurement methods include fluorescence edge scans, ptychography, and wavefront sensing. Among these, wavefront sensing emerges as the only single-shot option. In this approach, the wavefront downstream of the focal plane is captured and then backpropagated to pinpoint the focal plane and determine its associated size and position. Intensive efforts are in progress to refine and improve the resolution of this method.",
    "Conclusions": "This paper reports on an AI-driven system to achieve auto-alignment of nanofocusing KB-mirror systems within next-generation synchrotron radiation beamlines. Through the intricate development and comprehensive study of an ultra-realistic digital twin representing two distinct beamlines, we have systematically explored and refined the control system, verifying its applicability in real-world scenarios. Our successful experimental demonstration at a X-ray beamline using real focusing KB mirrors highlights the system's capability to create a focused beam and mold beam structures into specific shapes. Marking one of the pioneering steps towards complete automation of future beamline operation and optimization, this work aligns seamlessly with our previous studies that employed ML-based control systems for multi-variable adaptive mirror control. Together, these advancements forecast a significant breakthrough in beamline automation, unlocking scientific research avenues previously out of reach. This study not only confirms the feasibility of the new method but also establishes a robust foundation for anticipated future enhancements. We expect diligent refinement and continued testing, particularly in cutting-edge research domains such as Bayesian optimization and reinforcement learning, will unveil even more capabilities. These developments will serve as crucial elements in the toolkit of modern technological innovation, with potential impacts that could reshape our understanding of optics and automation. As a worth mentioning example, this work represents a significant step towards more complex applications, such as autonomous mirror-based zoom optics systems that can dynamically change focal spot sizes for in-situ experiments, such as electrochemical dissolution and growth, vital in fields like electrocatalysis, synthesis, and corrosion. Such dynamic control, adapting to sample sizes changing on a minute scale, demands optimization of many parameters—an almost impossible task manually. The algorithm developed here not only guides the optics to an optimal setup but maintains it, offering potential gains in accuracy and reliability for ML-driven controllers of Adaptive Optics (AOs) in correcting residual aberrations. This research paves the way for new capabilities in coherent nanoprobe beamlines, enabling experiments that track sub-nanometer structural evolution for various applications.",
    "A 1.1": "Fig. 1: (a) Photograph of the KB-mirror system at the 34-ID-C beamline and (b) schematic of the four-bar bender design. Each mirror is equipped with four motors, as shown in Fig. 1b. Motors 1 and 2 control upstream and downstream bending forces of the four-bar bender, respectively, while motor 3 adjusts the incident angle, and motor 4 moves the mirror position in the direction normal to its surface.",
    "A 1.2": "Fig. 2: KB-mirror system at 28-ID-B beamline: upbound-reflective, vertically focusing bimorph mirror, with visible 18 electrode pairs for the local shaping actuators and the optical surface sandwiched between the electrodes (a), schematic for substrate dimensions and the piezo electrode channels (b); outward-reflecting, horizontally focusing bendable mirror (c) and detail of the flexure bender (d).",
    "A 1.3": "Fig. 3: UML diagram of the software to drive the focusing system of 34-ID-C. The interface (34IDAbstractFocusingOptics) is implemented by both the hardware driver (right side of the diagram) and the digital twins (left side of the diagram, with different implementation corresponding to different simulation strategies).",
    "A 1.4": "Fig. 4: Screenshot of the Python code used to instantiate the focusing optics controller.",
    "A 1.5": "Fig. 5: Example of calibrated response function: upward bender motor of the horizontally focusing mirror at 34-ID-C.",
    "A 1.6": "Fig. 6: Comparison of simulated beam profiles (red line) with measured data collected at the 34-ID-C beamline (blue dotted line): at focus - horizontal (a) and vertical (b) profiles, out of focus (bender motors position +5 µm) - horizontal (c) and vertical (d) profiles.",
    "A 1.7": "Fig. 7: Measured (a) and simulated (b) beam images at the 28-ID-B beamline.",
    "A 1.8": "Fig. 8: MOBO auto-alignment for the 34-ID-C digital twin.(a) and (b) show the ID x and y beam profiles, respectively, obtained as data for the manually optimized reference structure (M), the initial structure (I), and the Nash solution (NS) structure. (c) The scatter plot for the optimization objectives (FWHM and PL) with the colors indicating the trial number. (d-i) show the actual 2D profiles (not used for the optimization) of the beam at the diffractometer position: (d) reference, (e) initial, (f) NS solution, and (g-i) other Pareto optimal beam profiles.",
    "A 1.9": "Fig. 9: MOBO auto-alignment for the 28-ID-B digital twin. (a) The manually tuned (M) focused structure. (b) The initial structure obtained by randomly shifting the parameters. (c) The Nash solution (NS) structure selected after the optimization. (d-e) Other structures in the Pareto front. Subplots (b-e) are similar to the corresponding subplots in Fig. 8, only with the addition of the peak intensity count (pl) information in the text boxes. (f-h) 2D projections of the 3D scatter plot of the optimization objectives with the colors indicating the trial number.",
    "A 1.10": "Fig. 10: MOBO auto-alignment experimental validation at the 28-IDB beamline. (A) The initial structure, (B) the Nash solution, and (C-E) the 2D projections of the 3D scatter plot of the optimization objectives, with the colors indicating the trial number and the circled points indicating the structures in the Pareto front.",
    "A 1.11": "Fig. 11: Alignment to a reference structure. (a) The random initial structure, (b) the Nash solution, and (c) the remaining structure in the Pareto front. (d) The change in the optimization objective through the optimization trials."
  }
}