{
  "filename": "Morris et al. - 2024 - A general Bayesian algorithm for the autonomous alignment of beamlines.pdf",
  "metadata": {
    "title": "A general Bayesian algorithm for the autonomous alignment of beamlines",
    "authors": [
      "Thomas W. Morris",
      "Max Rakitin",
      "Yonghua Du",
      "Mikhail Fedurin",
      "Abigail C. Giles",
      "Denis Leshchev",
      "William H. Li",
      "Brianna Romasky",
      "Eli Stavitski",
      "Andrew L. Walter",
      "Paul Moeller",
      "Boaz Nash",
      "Antoine Islegen-Wojdyla"
    ],
    "arxiv_id": ""
  },
  "sections": {
    "Abstract": "Autonomous methods to align beamlines can decrease the amount of time spent on diagnostics, and also uncover better global optima leading to better beam quality. The alignment of these beamlines is a high-dimensional expensive-to-sample optimization problem involving the simultaneous treatment of many optical elements with correlated and nonlinear dynamics. Bayesian optimization is a strategy of efficient global optimization that has proved successful in similar regimes in a wide variety of beamline alignment applications, though it has typically been implemented for particular beamlines and optimization tasks. In this paper, we present a basic formulation of Bayesian inference and Gaussian process models as they relate to multi-objective Bayesian optimization, as well as the practical challenges presented by beamline alignment. We show that the same general implementation of Bayesian optimization with special consideration for beamline alignment can quickly learn the dynamics of particular beamlines in an online fashion through hyperparameter fitting with no prior information. We present the implementation of a concise software framework for beamline alignment and test it on four different optimization problems for experiments on X-ray beamlines at the National Synchrotron Light Source II and the Advanced Light Source, and an electron beam at the Accelerator Test Facility, along with benchmarking on a simulated digital twin. We discuss new applications of the framework, and the potential for a unified approach to beamline alignment at synchrotron facilities.",
    "Introduction": "Synchrotron light sources are invaluable scientific tools that allow the probing of materials across bulk, micrometre and nanometre scales. These facilities perform a wide variety of research, with applications in the study of catalysis, biological function and materials science. Several next-generation synchrotron and free-electron laser facilities are scheduled to receive upgrades which will increase their brilliance by several orders of magnitude. However, more advanced experiments will require more precise and complex optical setups. Beamlines consist of a large number of optical components (e.g. mirrors, magnets, apertures), each with many degrees of freedom (corresponding to e.g. motors that translate, rotate and bend the components). These degrees of freedom can be highly correlated or degenerate, making beamline alignment in essence a high-dimensional (D>=10) and highly nonlinear optimization problem. This is typically done manually, and the design of optical systems is typically done to separate some of these dimensions and make manual alignment more feasible, e.g. by prefocusing and refocusing with a secondary-source aperture and a pair of Kirkpatrickâ€“Baez mirrors. Nevertheless, as the complexity and precision of beamlines grow, the development of efficient and robust automated alignment methods is necessary for the efficient operation of light sources now and in the future. Such methods allow us to reach an acceptable level of alignment more quickly and robustly than with manual methods when realignment is necessary, saving preparation and commissioning time which could be used for experiments. They further allow us potentially to find better global optima than an operator could discover manually by considering all dimensions of the beamline simultaneously. They also represent the first step toward a fully autonomous beamline.",
    "Bayesian optimization": "Consider an expensive-to-sample black-box function f(x) with d-dimensional inputs x. In finding the right input x to achieve the maximal value of f(x), it is untenable to utilize optimization methods that rely on lots of function samples. We can address this by treating the function as a stochastic process (which describes a distribution over all possible realizations of the function) and using Bayesian inference to construct a posterior distribution p(f), i.e. describing how likely it is that every possible function f is the true function. If we sample the function at points x = {x_1, x_2, ..., x_n} and observe values y = {f(x_1), f(x_2), ..., f(x_n)}, then we can use Bayesian inference to write our posterior belief about f given that we observe x and y as p(f|x, y) = [p(y|f, x)p(f)] / p(y|x), where p(y|f, x) is the likelihood, p(f) is the prior, and p(y|x) is the marginal likelihood. Each iteration of Bayesian optimization then consists of three steps: (i) Estimate the posterior p(f|y, x) from some historical observations (x, y). (ii) Use the posterior to find the most desirable point x* within some predefined bounds. (iii) Sample that point and add it to our historical observations.",
    "Gaussian process models": "A GP is a stochastic process where every collection of variables y has a multivariate normal distribution; for notational simplicity and without loss of generality, we assume throughout this paper that all of our processes are zero mean. The GP is described entirely by the covariance matrix Sigma describing the observations y. A GP model consists of assigning a covariance matrix to a set of sample data y at inputs x and computing the posterior mean and posterior variance at every other input. In practice, the covariance of the process is not known a priori and is approximated by constructing and fitting a kernel. To construct our kernel, we take the hyperparameters which maximize the marginal likelihood. Once we have our kernel K(x_i, x_j, theta) and optimized hyperparameters theta*, we can use GP regression to construct posteriors. It may be the case that our observations are noisy, i.e. that observing the function at points x will yield y = f(x) + epsilon where epsilon is a random noise term. If we assume that epsilon is homoskedastic and Gaussian, then we can account for the noise by adding a constant noise variance sigma^2 to the diagonal of the kernel K.",
    "Acquisition functions": "The acquisition function A(x) is a model of a given objective over possible inputs which, given a posterior p(f|x, y), quantifies the desirability of sampling a given input x. For each iteration of the optimization, we optimize the acquisition function over the inputs. Acquisition functions can be either analytic or non-analytic. Analytic acquisition functions are directly computable from the posterior; as the posterior for a GP is determined entirely by the mean mu and variance sigma, they may be expressed as A(x) = f(mu(x), sigma(x)). The simplest example is the expected mean, where on every iteration the algorithm will sample the point with the largest expected mean. A less risk-averse example is the expected improvement, which is our expectation for how much the cumulative maximum f* will increase if we were to sample x. Some useful acquisition functions cannot be computed directly from the mean and variance of the posterior. Acquisition functions that involve sampling from the posterior to estimate some ensemble are more flexible and often more robust. One example of this is in selecting multiple points, as in when we want to find the best n points to sample given some analytic acquisition function A(x). We address this interdependence with a Monte Carlo acquisition function, where we might evaluate the acquisition of some collection of points by sampling from the posterior and taking an ensemble average of the result.",
    "Beamline-specific considerations": "In this section, we look at beamline-specific considerations that improve the practical application of Bayesian optimization to the automated alignment problem. We consider the common optimization problem of maximizing the beam power density. Input parameters for beamlines can be highly coupled. In fitting GPs to beamline data, we adopt a kernel of the form k(x_i, x_j, theta) = f(|D exp S(x_i - x_j)|), where f(r) is some radial function, D is a diagonal matrix, and S is a skew-symmetric matrix. The application of Bayesian optimization relies on reliable diagnostic feedback, which is often not a realistic assumption for real-life scenarios. Undesirable behavior in the diagnostics can occur both sporadically or systematically. We use the classification method outlined by Milios et al. (2018) which fits a Dirichlet distribution to the data from which we can generate class probabilities. Using this probability, we can weight any objective-based acquisition function to prefer inputs that lead to valid outputs. Bayesian optimization is particularly useful when sampling the objective function f(x) is expensive. This is strictly true for some beamlines where computing a diagnostic is expensive. Many beamlines, though, have no latency in the diagnostics and are only expensive to sample because they are expensive to move around. Another challenge to machine learning-based optimization is hysteresis, which manifests at beamlines when the actual position of some input varies from the desired input. Even though we combine estimates of the different beam attributes into a scalar fitness to be maximized, it is still beneficial to construct and train three separate models for the flux, horizontal spread and vertical spread, a method typically referred to as composite optimization.",
    "Implementation": "Our beamline alignment tools are implemented in the Blop Python package, relying on the BoTorch Python package. In Blop we develop a customized kernel which fits to latent beamline dimensions and weight common acquisition functions by the probabilistic constraint. We also use BoTorch for model fitting and acquisition function optimization. The algorithm is used in terms of an agent, which we instantiate with motors and diagnostic equipment. We can 'tell' the agent about the values of pre-defined objectives and 'ask' it for new points to sample. The agent wraps the steps of Bayesian optimization into a single customizable routine. We have designed Blop with Bluesky in mind, as it can use Bluesky to automatically take data, analyze it and optimize the inputs with the same feedback and control systems used for beamline experiments.",
    "Experiments": "Alignment of a Kirkpatrick-Baez mirror system on the TES beamline: We optimize for the flux density on the sample by allowing each K-B mirror and the toroidal mirror to pitch and translate into and out of the beam for a total of six degrees of freedom. Alignment of a Johann spectrometer on the ISS beamline: Maximizing the flux on the area detector maximizes the resolution of the spectrometer and so we seek to colocate the reflections of the crystals onto the same point. We use three crystals to focus the beam onto a two-dimensional area detector. Photon transport optimization on the Advanced Light Source beamline 5.3.1: The photon transport system comprises a first focusing mirror, a monochromator and a few apertures. Using the described automated alignment, we were able to maximize the power density on the sample in under 5 min, with a final beam size of 1 mm x 0.3 mm (horizontal x vertical, FWHM). Alignment of an electron beam at the Accelerator Test Facility: We modulate three bending quadrupole electromagnets and a solenoid to manipulate the shape of the beam, for a total of four degrees of freedom. Simulated alignment of the TES beamline: We use digital twins of beamlines using the Sirepo-Bluesky back end, allowing us to optimize the beam with the same Bluesky-based code used to align real beamlines. The eight-dimensional optimization of the simulated TES beamline shows the benefit of using both latent inputs and composite outputs.",
    "Further development and discussion": "We have applied the same automated alignment tools to several different facilities and have shown that the same Python package can effectively align a range of beamlines. Further refinement of these automated alignment tools will involve applying them to more beamlines at more facilities, with different flavors of optimization problems. How practical automated alignment can be necessitates an intuitive graphical user interface, from which the configuration of the optimizer is easy to understand. Further development also includes the implementation of new features and better performance in the software. The enabling of Pareto efficient optimization would give the beamline scientist more control over the beam quality. We also plan to allow for a decentralized agent, which can run on a high-performance computing server and communicate with the control system using a streaming system like Kafka and feed back to the experiment control using Bluesky-Queueserver. Fly scanning, the strategy of sampling while moving parameters, presents the potential to speed up beamline alignment. We also note that the largest obstacle to applying automated alignment to existing beamlines is the difficulty in constructing robust feedbacks, as many beam diagnostics have non-negligible backgrounds or malfunctioning pixels. This suggests the benefit of more sophisticated diagnostic methods, using machine learning techniques like image segmentation.",
    "A 1.1": "Figure 1: The prior distribution, noiseless posterior distribution and noisy posterior distributions for a GP with covariance <f(x_i)f(x_j)> = M_{5/2}(|x_i - x_j|/l). For each distribution, we draw four random functions (colored lines). The black line represents the mean of each distribution, while the dark and light-shaded regions represent the 1sigma and 2sigma intervals, respectively.",
    "A 1.2": "Figure 2: An example of an iteration of a Bayesian optimization algorithm trying to maximize the negated Himmelblau function f(x_1, x_2) = -(x_1^2 + x_2 - 11)^2 - (x_1 + x_2^2 - 7)^2 whose true global optima are marked as white circles. Using existing data points and the assumption that the function is distributed as a GP, we can use Bayesian inference to compute a posterior consisting of a mean and error, upon which we can compute an acquisition function which informs us of the best points to sample. The black-edged diamonds superimposed on the acquisition function show the best eight points to sample, optimized in parallel and with the optimal routing represented by the red line.",
    "A 1.3": "Figure 3: (Upper left) The result of changing the positions of two coupled dimensions of the TES beamline. (Upper right) A quasi-random sample of 16 points from the ground truth. (Lower left) A non-latent GP fitted to the parameter space fitted to the sampled points. (Lower right) A latent GP fitted to the same points, which correctly infers the latent dimensions.",
    "A 1.4": "Figure 4: A schematic of the TES (8-BM) beamline at NSLS-II. This representation shows the many optical components that make up modern beamlines, with each optical component having many degrees of freedom that must be optimized in concert in order to carry out experiments effectively.",
    "A 1.5": "Figure 5: Four different beam configurations on the NSLS-II TES (8-BM) beamline, where the upper left-hand panel shows the initial beam and the lower right represents the optimal alignment. In this alignment test, we adjust the translation and rotation of each of the horizontal and vertical Kirkpatrick-Baez mirrors and the pitch and vertical translation of a toroidal mirror, for a total of six degrees of freedom to maximize the flux density of the beam.",
    "A 1.6": "Figure 6: Four different beam configurations on the NSLS-II ISS (8-ID) beamline during automated alignment, where the upper left-hand panel shows the initial beam and the lower right represents the optimal alignment. In this alignment test, we adjust the translation of a central crystal and the translation and pitch of two ancillary crystals for a total of five degrees of freedom to maximize the flux density of the total beam on the area detector.",
    "A 1.7": "Figure 7: A schematic of beamline 5.3.1 at the Advanced Light Source. The beamline has four degrees of freedom (toroidal mirror pitch and bend, and monochromator angle and height) and four constraints (four-jaw slits).",
    "A 1.8": "Figure 8: Four different beam configurations on the Advanced Light Source Beamline 5.3.1 during automated alignment. In total, the photon transport has four active degrees of freedom: the focusing mirror pitch and tangential bend, and the channel-cut crystal angle and height. The upper left-hand panel shows the initial manually aligned beam and the lower right the final beam after automated alignment. The upper right and lower left panels show intermediate points collected in the automated alignment process.",
    "A 1.9": "Figure 9: Four different electron beam configurations at the Brookhaven National Laboratory ATF at different stages of automated alignment, where the upper left-hand panel shows the starting beam and the lower right the optimal beam. In this alignment test, we tune the current of four quadrupole electromagnets to maximize the objective in equation (23).",
    "A 1.10": "Figure 10: The eight-dimensional optimization of the simulated TES beamline, where the degrees of freedom comprise the toroidal and Kirkpatrick-Baez mirrors. The colors show different varieties of Bayesian optimization algorithms both with and without latent inputs and composite outputs, with both the cumulative maximum of all individual runs (thin lines) and the median cumulative maximum (thick line). Each variety starts out with a quasi-random sampling of 32 points (shaded light blue) and then performs a Bayesian optimization loop with the expected improvement acquisition function. The benefit of using both latent inputs and composite outputs is shown, as we can achieve a better optimum more robustly and more quickly.",
    "A 1.11": "Figure 11: The four-dimensional optimization of just the K-B mirrors, whose motors are each misaligned by up to 0.05 mm. After an initial quasi-random sample of 16 points (shaded light blue), the agent is able almost instantly to return to the optimal alignment."
  }
}