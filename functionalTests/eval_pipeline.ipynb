{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed1b9735",
   "metadata": {},
   "source": [
    "# End-to-End RAG Pipeline - Evaluation\n",
    "\n",
    "Full RAG pipeline: PDF ingestion → Improved chunking → Embedding → ChromaDB → Retrieval → LLM answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed9810b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: c:\\Users\\kronask\\OneDrive - TU Wien\\TU Wien\\3. Semester\\GenAI\\GenAI\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Change to parent directory for config.yaml access\n",
    "parent_dir = Path.cwd().parent\n",
    "os.chdir(parent_dir)\n",
    "sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "from pdfProcessing.docling_PDF_processor import DoclingPDFProcessor\n",
    "from pdfProcessing.chunking import create_chunks_from_sections\n",
    "from embeddingModels.ModernBertEmbedder import ModernBertEmbedder\n",
    "from embeddingModels.QwenEmbedder import QwenEmbedder\n",
    "from backend.services.embedder import EmbeddingService\n",
    "from backend.services.vector_db import VectorDBService\n",
    "from backend.services.rag_answer_service import ChromaRagRetriever\n",
    "from llmAG.rag.pipeline import RagPipeline\n",
    "from llmAG.llm import build_llm\n",
    "from zotero_integration.metadata_loader import ZoteroMetadataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1bb01b",
   "metadata": {},
   "source": [
    "## 1. Initialize Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "296ffd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Zotero metadata loader...\n",
      "Loaded 24 items from zotero_export_20260112_191851.json\n",
      "✓ Zotero metadata loaded\n",
      "Initializing PDF processor...\n",
      "Initializing Docling Converter...\n",
      "CUDA detected. Using GPU for PDF Processing.\n",
      "Initializing embedding service...\n",
      "Loading Model Key: bert...\n",
      "Loading Alibaba-NLP/gte-modernbert-base on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-17 19:59:01,098 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ChromaDB...\n",
      "Initializing LLM (Ollama mistral-nemo)...\n",
      "✓ LLM initialized\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "EMBEDDER_TYPE = \"bert\"  # \"bert\" or \"qwen\"\n",
    "CHROMA_PATH = \"./backend/chroma_db\"  # Use same DB as backend\n",
    "MAX_CHUNK_SIZE = 2500\n",
    "OVERLAP_SIZE = 200\n",
    "TOP_K_RETRIEVAL = 5\n",
    "\n",
    "# Database Management\n",
    "CLEAR_DB_ON_RUN = False  # Set to True to clear DB and re-ingest all PDFs\n",
    "\n",
    "# Set Ollama URL for local execution (not Docker)\n",
    "os.environ[\"OLLAMA_BASE_URL\"] = \"http://localhost:11434\"\n",
    "\n",
    "# Initialize Zotero metadata loader\n",
    "print(\"Initializing Zotero metadata loader...\")\n",
    "try:\n",
    "    zotero_loader = ZoteroMetadataLoader()\n",
    "    print(f\"✓ Zotero metadata loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Zotero metadata not available: {e}\")\n",
    "    print(\"  Will fall back to Docling extraction\")\n",
    "    zotero_loader = None\n",
    "\n",
    "# Initialize PDF processor\n",
    "print(\"Initializing PDF processor...\")\n",
    "processor = DoclingPDFProcessor()\n",
    "\n",
    "# Initialize embedding service\n",
    "print(\"Initializing embedding service...\")\n",
    "embed_service = EmbeddingService()\n",
    "# Load the model to have direct access to embedder for manual operations\n",
    "embedder = embed_service.load_model(EMBEDDER_TYPE)\n",
    "\n",
    "# Initialize ChromaDB service\n",
    "print(\"Initializing ChromaDB...\")\n",
    "db_service = VectorDBService(\n",
    "    db_path=CHROMA_PATH,\n",
    "    collection_names={\n",
    "        \"bert\": \"scientific_papers_bert\",\n",
    "        \"qwen\": \"scientific_papers_qwen\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Initialize LLM\n",
    "print(\"Initializing LLM (Ollama mistral-nemo)...\")\n",
    "try:\n",
    "    llm = build_llm(model=\"mistral-nemo\", temperature=0.1)\n",
    "    print(\"✓ LLM initialized\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ LLM initialization failed: {e}\")\n",
    "    print(\"  Make sure Ollama app is running (check system tray)\")\n",
    "    llm = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e33fbc",
   "metadata": {},
   "source": [
    "## 2. Database Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c987461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATABASE STATUS\n",
      "================================================================================\n",
      "Current database status (model: bert)\n",
      "  Chunks in database: 538\n",
      "  ✓ Database ready for evaluation\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Check current database state\n",
    "print(f\"{'='*80}\")\n",
    "print(\"DATABASE STATUS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "try:\n",
    "    collection = db_service.get_collection(EMBEDDER_TYPE)\n",
    "    chunk_count = collection.count()\n",
    "    \n",
    "    print(f\"Current database status (model: {EMBEDDER_TYPE})\")\n",
    "    print(f\"  Chunks in database: {chunk_count}\")\n",
    "    \n",
    "    if chunk_count == 0:\n",
    "        print(f\"  ⚠ Database is empty - run ingestion first\")\n",
    "    else:\n",
    "        print(f\"  ✓ Database ready for evaluation\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error checking database: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808221d2",
   "metadata": {},
   "source": [
    "## 3. Load Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5d26c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 32 questions from eval_dataset.json\n"
     ]
    }
   ],
   "source": [
    "def load_eval_dataset(filename=\"eval_dataset.json\"):\n",
    "    file_path = Path.cwd() / filename\n",
    "    \n",
    "    if not file_path.exists():\n",
    "        print(f\"⚠ Warning: {filename} not found in {Path.cwd()}\")\n",
    "        return []\n",
    "        \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    print(f\"✓ Loaded {len(data)} questions from {filename}\")\n",
    "    return data\n",
    "\n",
    "# Load the data\n",
    "eval_dataset = load_eval_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1c065b",
   "metadata": {},
   "source": [
    "## 4. Initialize RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "369d3045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RAG pipeline initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize RAG components\n",
    "retriever = ChromaRagRetriever(\n",
    "    embed_service=embed_service,\n",
    "    db_service=db_service,\n",
    "    model_name=EMBEDDER_TYPE\n",
    ")\n",
    "\n",
    "# Initialize RAG pipeline (builds LLM internally)\n",
    "rag_pipeline = RagPipeline(\n",
    "    retriever=retriever,\n",
    "    model=\"mistral-nemo\",\n",
    "    temperature=0.1\n",
    ")\n",
    "print(\"✓ RAG pipeline initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c5ead7",
   "metadata": {},
   "source": [
    "## 5. RAG Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19110433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation of 32 questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "2026-01-17 19:59:19,848 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "  3%|▎         | 1/32 [00:15<08:02, 15.56s/it]2026-01-17 19:59:29,349 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "  6%|▋         | 2/32 [00:32<08:07, 16.26s/it]2026-01-17 19:59:46,789 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "  9%|▉         | 3/32 [00:40<05:58, 12.36s/it]2026-01-17 19:59:53,247 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 12%|█▎        | 4/32 [00:46<04:41, 10.06s/it]2026-01-17 20:00:01,427 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 16%|█▌        | 5/32 [00:55<04:23,  9.77s/it]2026-01-17 20:00:10,922 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 19%|█▉        | 6/32 [01:08<04:36, 10.64s/it]2026-01-17 20:00:22,979 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 22%|██▏       | 7/32 [01:28<05:48, 13.92s/it]2026-01-17 20:00:44,206 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 25%|██▌       | 8/32 [01:49<06:26, 16.10s/it]2026-01-17 20:01:03,904 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 28%|██▊       | 9/32 [02:00<05:34, 14.54s/it]2026-01-17 20:01:14,518 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 31%|███▏      | 10/32 [02:16<05:31, 15.05s/it]2026-01-17 20:01:31,247 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 34%|███▍      | 11/32 [02:48<07:03, 20.17s/it]2026-01-17 20:02:03,002 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 38%|███▊      | 12/32 [03:12<07:03, 21.19s/it]2026-01-17 20:02:26,679 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 41%|████      | 13/32 [03:22<05:38, 17.81s/it]2026-01-17 20:02:35,950 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 44%|████▍     | 14/32 [03:44<05:42, 19.02s/it]2026-01-17 20:02:58,359 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 47%|████▋     | 15/32 [03:57<04:54, 17.33s/it]2026-01-17 20:03:11,635 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 50%|█████     | 16/32 [04:05<03:52, 14.53s/it]2026-01-17 20:03:19,130 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 53%|█████▎    | 17/32 [04:36<04:51, 19.41s/it]2026-01-17 20:03:50,985 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 56%|█████▋    | 18/32 [05:19<06:10, 26.44s/it]2026-01-17 20:04:33,829 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 59%|█████▉    | 19/32 [06:12<07:27, 34.41s/it]2026-01-17 20:05:26,357 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 62%|██████▎   | 20/32 [06:39<06:29, 32.43s/it]2026-01-17 20:05:54,761 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 66%|██████▌   | 21/32 [06:52<04:50, 26.39s/it]2026-01-17 20:06:06,436 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 69%|██████▉   | 22/32 [07:07<03:51, 23.12s/it]2026-01-17 20:06:22,611 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 72%|███████▏  | 23/32 [08:11<05:17, 35.26s/it]2026-01-17 20:07:24,948 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 75%|███████▌  | 24/32 [09:01<05:17, 39.70s/it]2026-01-17 20:08:15,614 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 78%|███████▊  | 25/32 [09:32<04:21, 37.30s/it]2026-01-17 20:08:46,550 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 81%|████████▏ | 26/32 [10:11<03:46, 37.79s/it]2026-01-17 20:09:26,714 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 84%|████████▍ | 27/32 [10:44<03:01, 36.34s/it]2026-01-17 20:09:58,735 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 88%|████████▊ | 28/32 [12:19<03:35, 53.94s/it]2026-01-17 20:11:34,166 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 91%|█████████ | 29/32 [12:33<02:05, 41.95s/it]2026-01-17 20:11:47,507 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 94%|█████████▍| 30/32 [12:58<01:13, 36.82s/it]2026-01-17 20:12:12,427 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 97%|█████████▋| 31/32 [14:22<00:50, 50.79s/it]2026-01-17 20:13:35,526 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 32/32 [15:03<00:00, 28.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation Summary ===\n",
      "Retrieval Hit Rate (Targeted Questions): 74.07%\n",
      "Average Latency: 28.24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Tier",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Target_Tag",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Hit",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Answer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sources",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Latency",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "8018aa92-a53d-4eb1-a389-5653e313daad",
       "rows": [
        [
         "0",
         "1",
         "What does the acronym ERD stand for, and what role does it play in the sampling pipeline?",
         "FAST",
         "False",
         "I do not know based on the provided context because the retrieved sections do not mention ERD or its role in the sampling pipeline. Would you like me to find related papers online?",
         "a general bayesian algorithm for the autonomous al... | performance metrics to unleash the power of self-d... | self-driving laboratories for chemistry and materi... | performance metrics to unleash the power of self-d... | self-driving laboratories for chemistry and materi...",
         "15.56"
        ],
        [
         "1",
         "1",
         "What is the size of the test dark-field image (in pixels), and how many candidate measurement positions does that imply?",
         "FAST",
         "False",
         "Based on the provided context:\n\n- The size of the test dark-field image is not explicitly stated in the retrieved sections.\n- The number of candidate measurement positions is also not mentioned directly.\n\nTherefore, I do not know based on the provided context because the retrieved sections do not mention this. Would you like me to find related papers online?",
         "autofocus: ai-driven alignment of nanofocusing x-r... | a general bayesian algorithm for the autonomous al... | a general bayesian algorithm for the autonomous al... | laboratory experiments of model-based reinforcemen... | laboratory experiments of model-based reinforcemen...",
         "16.76"
        ],
        [
         "2",
         "1",
         "Name the static sampling baselines used for comparison.",
         "FAST",
         "False",
         "The static sampling baselines used for comparison are not explicitly mentioned in the provided context. Would you like me to find related papers online?",
         "a general bayesian algorithm for the autonomous al... | self-driving laboratories for chemistry and materi... | a general bayesian algorithm for the autonomous al... | inverse design of chiral functional films by a rob... | a general bayesian algorithm for the autonomous al...",
         "7.7"
        ],
        [
         "3",
         "1",
         "What is the initial scan coverage (%) used before adaptive selection begins?",
         "FAST",
         "False",
         "I do not know based on the provided context because the retrieved sections do not mention this. Would you like me to find related papers online?",
         "a general bayesian algorithm for the autonomous al... | the rise of data‐driven microscopy powered by mach... | a general bayesian algorithm for the autonomous al... | self-driving laboratories for chemistry and materi... | laboratory experiments of model-based reinforcemen...",
         "6.54"
        ],
        [
         "4",
         "1",
         "How many new points are acquired per iteration during the adaptive scan?",
         "FAST",
         "True",
         "The context does not mention how many new points are acquired per iteration during the adaptive scan. Would you like me to find related papers online?",
         "deep reinforcement learning for data-driven adapti... | deep reinforcement learning for data-driven adapti... | deep reinforcement learning for data-driven adapti... | a general bayesian algorithm for the autonomous al... | demonstration of an ai-driven workflow for autonom...",
         "9.25"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tier</th>\n",
       "      <th>Question</th>\n",
       "      <th>Target_Tag</th>\n",
       "      <th>Hit</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Sources</th>\n",
       "      <th>Latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What does the acronym ERD stand for, and what ...</td>\n",
       "      <td>FAST</td>\n",
       "      <td>False</td>\n",
       "      <td>I do not know based on the provided context be...</td>\n",
       "      <td>a general bayesian algorithm for the autonomou...</td>\n",
       "      <td>15.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the size of the test dark-field image ...</td>\n",
       "      <td>FAST</td>\n",
       "      <td>False</td>\n",
       "      <td>Based on the provided context:\\n\\n- The size o...</td>\n",
       "      <td>autofocus: ai-driven alignment of nanofocusing...</td>\n",
       "      <td>16.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Name the static sampling baselines used for co...</td>\n",
       "      <td>FAST</td>\n",
       "      <td>False</td>\n",
       "      <td>The static sampling baselines used for compari...</td>\n",
       "      <td>a general bayesian algorithm for the autonomou...</td>\n",
       "      <td>7.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the initial scan coverage (%) used bef...</td>\n",
       "      <td>FAST</td>\n",
       "      <td>False</td>\n",
       "      <td>I do not know based on the provided context be...</td>\n",
       "      <td>a general bayesian algorithm for the autonomou...</td>\n",
       "      <td>6.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>How many new points are acquired per iteration...</td>\n",
       "      <td>FAST</td>\n",
       "      <td>True</td>\n",
       "      <td>The context does not mention how many new poin...</td>\n",
       "      <td>deep reinforcement learning for data-driven ad...</td>\n",
       "      <td>9.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tier                                           Question Target_Tag    Hit  \\\n",
       "0     1  What does the acronym ERD stand for, and what ...       FAST  False   \n",
       "1     1  What is the size of the test dark-field image ...       FAST  False   \n",
       "2     1  Name the static sampling baselines used for co...       FAST  False   \n",
       "3     1  What is the initial scan coverage (%) used bef...       FAST  False   \n",
       "4     1  How many new points are acquired per iteration...       FAST   True   \n",
       "\n",
       "                                              Answer  \\\n",
       "0  I do not know based on the provided context be...   \n",
       "1  Based on the provided context:\\n\\n- The size o...   \n",
       "2  The static sampling baselines used for compari...   \n",
       "3  I do not know based on the provided context be...   \n",
       "4  The context does not mention how many new poin...   \n",
       "\n",
       "                                             Sources  Latency  \n",
       "0  a general bayesian algorithm for the autonomou...    15.56  \n",
       "1  autofocus: ai-driven alignment of nanofocusing...    16.76  \n",
       "2  a general bayesian algorithm for the autonomou...     7.70  \n",
       "3  a general bayesian algorithm for the autonomou...     6.54  \n",
       "4  deep reinforcement learning for data-driven ad...     9.25  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "class RAGEvaluator:\n",
    "    def __init__(self, pipeline):\n",
    "        self.pipeline = pipeline\n",
    "        self.results = []\n",
    "\n",
    "    def evaluate(self, dataset, top_k=5):\n",
    "        print(f\"Starting evaluation of {len(dataset)} questions...\")\n",
    "        self.results = []\n",
    "        \n",
    "        for item in tqdm(dataset):\n",
    "            question = item['question']\n",
    "            target_tag = item.get('target_tag')\n",
    "            tier = item.get('tier')\n",
    "            \n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                # Run RAG Pipeline\n",
    "                response = self.pipeline.run(question, k=top_k, include_sources=True)\n",
    "                elapsed = time.time() - start_time\n",
    "                \n",
    "                # 1. Retrieval Evaluation (Source Matching)\n",
    "                # Check if ANY of the retrieved docs contain the target tag in their title\n",
    "                retrieved_titles = [src.metadata.get('title', '').lower() for src in response.sources]\n",
    "                \n",
    "                hit = False\n",
    "                if target_tag:\n",
    "                    tag_map = {\n",
    "                        \"FAST\": [\"fast\", \"autonomous high-resolution scanning\"],\n",
    "                        \"liquid lenses\": [\"liquid lenses\", \"zhang\"],\n",
    "                        \"autofocus\": [\"autofocus\", \"zhang\", \"rebuffi\"],\n",
    "                        \"ptychography\": [\"ptychography\", \"schloz\"],\n",
    "                        \"alignment\": [\"alignment\", \"morris\", \"beamlines\"],\n",
    "                        \"optics\": [\"adaptive optics\", \"nousiainen\", \"mareev\"]\n",
    "                    }\n",
    "                    \n",
    "                    search_terms = tag_map.get(target_tag, [target_tag.lower()])\n",
    "                    \n",
    "                    # Check for hit\n",
    "                    for title in retrieved_titles:\n",
    "                        if any(term in title for term in search_terms):\n",
    "                            hit = True\n",
    "                            break\n",
    "                else:\n",
    "                    hit = None # No target tag defined (Synthesis questions)\n",
    "\n",
    "                # Store Result\n",
    "                self.results.append({\n",
    "                    \"Tier\": tier,\n",
    "                    \"Question\": question,\n",
    "                    \"Target_Tag\": target_tag,\n",
    "                    \"Hit\": hit,\n",
    "                    \"Answer\": response.answer,\n",
    "                    \"Sources\": \" | \".join([t[:50] + \"...\" for t in retrieved_titles]),\n",
    "                    \"Latency\": round(elapsed, 2)\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error on question: {question[:30]}... {e}\")\n",
    "                self.results.append({\n",
    "                    \"Tier\": tier,\n",
    "                    \"Question\": question,\n",
    "                    \"Target_Tag\": target_tag,\n",
    "                    \"Hit\": False,\n",
    "                    \"Answer\": f\"ERROR: {str(e)}\",\n",
    "                    \"Sources\": \"\",\n",
    "                    \"Latency\": 0\n",
    "                })\n",
    "\n",
    "        return pd.DataFrame(self.results)\n",
    "\n",
    "# Initialize and Run\n",
    "evaluator = RAGEvaluator(rag_pipeline)\n",
    "df_results = evaluator.evaluate(eval_dataset, top_k=5)\n",
    "\n",
    "# Display Summary\n",
    "print(\"\\n=== Evaluation Summary ===\")\n",
    "if 'Hit' in df_results.columns:\n",
    "    # Filter out synthesis questions (Hit=None) for accuracy calc\n",
    "    measurable = df_results.dropna(subset=['Hit'])\n",
    "    print(f\"Retrieval Hit Rate (Targeted Questions): {measurable['Hit'].mean():.2%}\")\n",
    "\n",
    "print(f\"Average Latency: {df_results['Latency'].mean():.2f}s\")\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28bf0be",
   "metadata": {},
   "source": [
    "## 6. Save and Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbca5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to rag_evaluation_results.csv\n",
      "\n",
      "=== Missed Retrieval Questions ===\n",
      "Q: What does the acronym ERD stand for, and what role does it play in the sampling pipeline?\n",
      "Target: FAST\n",
      "Got Sources: a general bayesian algorithm for the autonomous al... | performance metrics to unleash the power of self-d... | self-driving laboratories for chemistry and materi... | performance metrics to unleash the power of self-d... | self-driving laboratories for chemistry and materi...\n",
      "\n",
      "Q: What is the size of the test dark-field image (in pixels), and how many candidate measurement positions does that imply?\n",
      "Target: FAST\n",
      "Got Sources: autofocus: ai-driven alignment of nanofocusing x-r... | a general bayesian algorithm for the autonomous al... | a general bayesian algorithm for the autonomous al... | laboratory experiments of model-based reinforcemen... | laboratory experiments of model-based reinforcemen...\n",
      "\n",
      "Q: Name the static sampling baselines used for comparison.\n",
      "Target: FAST\n",
      "Got Sources: a general bayesian algorithm for the autonomous al... | self-driving laboratories for chemistry and materi... | a general bayesian algorithm for the autonomous al... | inverse design of chiral functional films by a rob... | a general bayesian algorithm for the autonomous al...\n",
      "\n",
      "Q: What is the initial scan coverage (%) used before adaptive selection begins?\n",
      "Target: FAST\n",
      "Got Sources: a general bayesian algorithm for the autonomous al... | the rise of data‐driven microscopy powered by mach... | a general bayesian algorithm for the autonomous al... | self-driving laboratories for chemistry and materi... | laboratory experiments of model-based reinforcemen...\n",
      "\n",
      "Q: If the full grid is 200 x 40, how many points is that total, and how many points correspond to 20% coverage?\n",
      "Target: FAST\n",
      "Got Sources: a general bayesian algorithm for the autonomous al... | a general bayesian algorithm for the autonomous al... | a general bayesian algorithm for the autonomous al... | the rise of data‐driven microscopy powered by mach... | self-driving laboratories for chemistry and materi...\n",
      "\n",
      "Q: What value of k is used for k-nearest neighbors, and what time complexity (Big-O) is stated for the method?\n",
      "Target: FAST\n",
      "Got Sources: a general bayesian algorithm for the autonomous al... | self-driving laboratories for chemistry and materi... | performance metrics to unleash the power of self-d... | self-driving laboratories for chemistry and materi... | self-driving laboratories for chemistry and materi...\n",
      "\n",
      "Q: Why are Gaussian Processes included as a comparator in FAST, and what scaling drawback is highlighted?\n",
      "Target: FAST\n",
      "Got Sources: a general bayesian algorithm for the autonomous al... | a general bayesian algorithm for the autonomous al... | inverse design of chiral functional films by a rob... | a general bayesian algorithm for the autonomous al... | a general bayesian algorithm for the autonomous al...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_filename = \"rag_evaluation_results.csv\"\n",
    "df_results.to_csv(output_filename, index=False)\n",
    "print(f\"Results saved to {output_filename}\")\n",
    "\n",
    "# Inspect specifically the \"Missed\" items to debug retrieval\n",
    "print(\"\\n=== Missed Retrieval Questions ===\")\n",
    "missed = df_results[(df_results['Hit'] == False) & (df_results['Target_Tag'].notna())]\n",
    "if not missed.empty:\n",
    "    for _, row in missed.iterrows():\n",
    "        print(f\"Q: {row['Question']}\")\n",
    "        print(f\"Target: {row['Target_Tag']}\")\n",
    "        print(f\"Got Sources: {row['Sources']}\\n\")\n",
    "else:\n",
    "    print(\"Great! No retrieval misses on targeted questions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fa9749",
   "metadata": {},
   "source": [
    "## 7. Detailed Evaluation by Tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14184a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EVALUATION BREAKDOWN BY TIER\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Tier 1:\n",
      "  Total Questions: 11\n",
      "  Retrieval Hit Rate: 63.64% (7/11)\n",
      "  Avg Latency: 15.33s\n",
      "\n",
      "Tier 2:\n",
      "  Total Questions: 12\n",
      "  Retrieval Hit Rate: 75.00% (9/12)\n",
      "  Avg Latency: 26.88s\n",
      "\n",
      "Tier 3:\n",
      "  Total Questions: 9\n",
      "  Retrieval Hit Rate: 100.00% (4/4)\n",
      "  Avg Latency: 45.83s\n"
     ]
    }
   ],
   "source": [
    "# Breakdown by tier and target tag\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"EVALUATION BREAKDOWN BY TIER\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "for tier in sorted(df_results['Tier'].unique()):\n",
    "    tier_data = df_results[df_results['Tier'] == tier]\n",
    "    print(f\"\\nTier {tier}:\")\n",
    "    print(f\"  Total Questions: {len(tier_data)}\")\n",
    "    \n",
    "    with_tags = tier_data[tier_data['Target_Tag'].notna()]\n",
    "    if len(with_tags) > 0:\n",
    "        hit_rate = with_tags['Hit'].mean()\n",
    "        print(f\"  Retrieval Hit Rate: {hit_rate:.2%} ({int(with_tags['Hit'].sum())}/{len(with_tags)})\")\n",
    "    \n",
    "    print(f\"  Avg Latency: {tier_data['Latency'].mean():.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc7a60b",
   "metadata": {},
   "source": [
    "## 8. Question-Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f23a202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ALL EVALUATION RESULTS\n",
      "================================================================================\n",
      "\n",
      "    Tier     Target_Tag                                                                                                                                                        Question    Hit  Latency\n",
      "0      1           FAST                                                                       What does the acronym ERD stand for, and what role does it play in the sampling pipeline?  False    15.56\n",
      "1      1           FAST                                        What is the size of the test dark-field image (in pixels), and how many candidate measurement positions does that imply?  False    16.76\n",
      "2      1           FAST                                                                                                         Name the static sampling baselines used for comparison.  False     7.70\n",
      "3      1           FAST                                                                                    What is the initial scan coverage (%) used before adaptive selection begins?  False     6.54\n",
      "4      1           FAST                                                                                        How many new points are acquired per iteration during the adaptive scan?   True     9.25\n",
      "5      1  liquid lenses                                                   What physical quantity is the controller changing (the actuator variable) in the liquid-lens autofocus setup?   True    12.33\n",
      "6      1      autofocus                                                                                  Which classic search methods are used as baselines in the DRL autofocus paper?   True    20.67\n",
      "7      1   ptychography                                                              What is the main objective of 'adaptive scanning' compared to a fixed raster grid in ptychography?   True    20.76\n",
      "8      1   ptychography                                                                                            What does the metric QSSIM represent in the ptychography evaluation?   True    11.13\n",
      "9      1      alignment                                                            What are the discrete actions available to the agent (action space) in the DQN beam alignment paper?   True    16.19\n",
      "10     1         optics                                                   What are the two main limitations of a well-tuned integrator controller that motivate RL for adaptive optics?   True    31.77\n",
      "11     2           FAST                                                       What batch size (number of points) is chosen for acquisition in FAST, and what practical reason is given?   True    23.51\n",
      "12     2           FAST                                                     At roughly what scan coverage does reconstruction quality 'stabilize' in FAST (based on SSIM/NRMSE trends)?   True    10.05\n",
      "13     2           FAST                                                    If the full grid is 200 x 40, how many points is that total, and how many points correspond to 20% coverage?  False    21.82\n",
      "14     2           FAST                                                 Which specific workflow design choice is described as the primary contributor to the large time saving in FAST?   True    13.39\n",
      "15     2           FAST                                                     What value of k is used for k-nearest neighbors, and what time complexity (Big-O) is stated for the method?  False     8.03\n",
      "16     2           FAST                                                          Why are Gaussian Processes included as a comparator in FAST, and what scaling drawback is highlighted?  False    30.76\n",
      "17     2      autofocus                                                    List the reward hyperparameters (e.g., alpha, beta, mu, delta) for DRL autofocus and what each incentivizes.   True    42.82\n",
      "18     2      autofocus                                                             What are the two action-set designs in the DRL autofocus paper and how do they differ conceptually?   True    52.98\n",
      "19     2      autofocus                                                   What is the reported speed improvement versus a named baseline in DRL autofocus, and what is the speed proxy?   True    27.80\n",
      "20     2   ptychography                             What are the ROP reconstruction settings (batch size, step size) and the approximate reconstruction time reported for ptychography?   True    12.31\n",
      "21     2   ptychography                                        Summarize the encoder/feature-extractor architecture used to represent partial scans in the adaptive ptychography paper.   True    15.49\n",
      "22     2         optics                     From the main hyperparameter table in the AO RL paper: what are episode length, warm-up episodes, replay buffer size, and planning horizon?   True    63.58\n",
      "23     3           None                          Compare the utility/decision signal FAST uses vs. the reward metrics in adaptive ptychography. Why does each make sense in its domain?   None    50.05\n",
      "24     3           FAST                                          How does FAST define 'scanning efficiency,' and in what way is this fundamentally different from raster-grid scanning?   True    31.70\n",
      "25     3           None  Compare how at least two different papers address the trade-off between image quality and sample damage/dose. What is each paper's 'knob' for reducing damage?   None    38.95\n",
      "26     3      autofocus                           Why might discretizing the action space improve stability or convergence compared to continuous control in the DRL autofocus setting?   True    32.94\n",
      "27     3           None                          Contrast the observation/state and reward shaping between DQN alignment and DRL autofocus; explain why the reward needs are different.   None    94.99\n",
      "28     3   ptychography                             The ptychography paper uses a particular discount factor setting (e.g., gamma = 0). Why is that choice made and what does it imply?   True    13.98\n",
      "29     3           FAST                                     Where does the exploration–exploitation trade-off appear in FAST results/figures, and what mitigation strategy is proposed?   True    24.84\n",
      "30     3           None                                                         List the main latency bottlenecks mentioned across at least two papers and the optimizations suggested.   None    83.40\n",
      "31     3           None                                                Identify two domain-shift risks (new sample types, new optics, etc.) and how each paper attempts to handle them.   None    41.66\n"
     ]
    }
   ],
   "source": [
    "# Show all questions with their results\n",
    "display_cols = ['Tier', 'Target_Tag', 'Question', 'Hit', 'Latency']\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ALL EVALUATION RESULTS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 80)\n",
    "\n",
    "print(df_results[display_cols].to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
