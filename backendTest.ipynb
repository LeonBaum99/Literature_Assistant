{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-03T16:48:47.570740200Z",
     "start_time": "2026-01-03T16:48:47.561112300Z"
    }
   },
   "source": [
    "import requests\n",
    "import json"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T13:03:44.024121700Z",
     "start_time": "2026-01-02T13:02:56.859808800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "url = \"http://localhost:8000/ingest\"\n",
    "file_path = \"data/testPDFs/BERT.pdf\"\n",
    "\n",
    "# We open the file in binary mode\n",
    "with open(file_path, \"rb\") as f:\n",
    "    files = {\"file\": f}\n",
    "    # We send the model choice as form data\n",
    "    data = {\"model_name\": \"bert\"}\n",
    "\n",
    "    print(f\"üì§ Uploading {file_path}...\")\n",
    "    response = requests.post(url, files=files, data=data)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"‚úÖ Ingestion Success!\")\n",
    "    print(response.json())\n",
    "else:\n",
    "    print(f\"‚ùå Error {response.status_code}: {response.text}\")"
   ],
   "id": "3b9a42d3bb1ef0de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ Uploading data/testPDFs/BERT.pdf...\n",
      "‚úÖ Ingestion Success!\n",
      "{'filename': 'BERT.pdf', 'message': 'Ingestion successful', 'chunks_added': 31, 'parent_id': 'arXiv:1810.04805v2'}\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T13:03:51.655815700Z",
     "start_time": "2026-01-02T13:03:49.890125400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "url = \"http://localhost:8000/query\"\n",
    "payload = {\n",
    "    \"query_text\": \"What are the architecture details of the transformer?\",\n",
    "    \"n_results\": 2,\n",
    "    \"model_name\": \"bert\"\n",
    "}\n",
    "\n",
    "print(f\"üîç Searching for: '{payload['query_text']}'\")\n",
    "response = requests.post(url, json=payload)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    results = data.get(\"results\", [])\n",
    "\n",
    "    print(f\"‚úÖ Found {len(results)} matches:\\n\")\n",
    "    for res in results:\n",
    "        print(f\"üìÑ Doc ID: {res['doc_id']}\")\n",
    "        print(f\"üìä Score:  {res['score']:.4f}\")\n",
    "        print(f\"üìù Content: {res['content'][:100]}...\") # Preview first 100 chars\n",
    "        print(\"-\" * 30)\n",
    "else:\n",
    "    print(f\"‚ùå Error {response.status_code}: {response.text}\")"
   ],
   "id": "e8204d15f36903ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching for: 'What are the architecture details of the transformer?'\n",
      "‚úÖ Found 2 matches:\n",
      "\n",
      "üìÑ Doc ID: arXiv:1810.04805v2#4_Experiments\n",
      "üìä Score:  0.4823\n",
      "üìù Content: In this section, we present BERT fine-tuning results on 11 NLP tasks....\n",
      "------------------------------\n",
      "üìÑ Doc ID: arXiv:1810.04805v2#2.2_Unsupervised_Fine-tuning_Approaches\n",
      "üìä Score:  0.4918\n",
      "üìù Content: As with the feature-based approaches, the first works in this direction only pre-trained word embedd...\n",
      "------------------------------\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T13:03:57.990317400Z",
     "start_time": "2026-01-02T13:03:57.588324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Deleting specific documents\n",
    "url = \"http://localhost:8000/delete\"\n",
    "payload = {\n",
    "    \"model_name\": \"bert\",\n",
    "    \"doc_ids\": [\"arXiv_1706.03762v7#Introduction\", \"arXiv_1706.03762v7#Conclusion\"]\n",
    "}\n",
    "requests.post(url, json=payload)"
   ],
   "id": "4303e869272b7f7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T13:04:10.819257800Z",
     "start_time": "2026-01-02T13:04:10.373275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Resetting the entire collection for a model\n",
    "url = \"http://localhost:8000/reset\"\n",
    "payload = {\"model_name\": \"bert\"}\n",
    "requests.post(url, json=payload)"
   ],
   "id": "ae7780165ccc755a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T13:04:02.475690Z",
     "start_time": "2026-01-02T13:04:02.447184200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# List items in the collection\n",
    "url = \"http://localhost:8000/list-ids\"\n",
    "\n",
    "params = {\n",
    "    \"model_name\": \"bert\",\n",
    "    \"limit\": 5\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "print(response.json())"
   ],
   "id": "7abeeefdf43a7fae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'bert', 'ids': ['arXiv:1810.04805v2#Preamble', 'arXiv:1810.04805v2#BERT:_Pre-training_of_Deep_Bidirectional_Transform', 'arXiv:1810.04805v2#Abstract', 'arXiv:1810.04805v2#1_Introduction', 'arXiv:1810.04805v2#2_Related_Work'], 'total_in_batch': 5}\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T13:04:14.853180700Z",
     "start_time": "2026-01-02T13:04:14.811167500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Debug embeddings for a specific text\n",
    "url = \"http://localhost:8000/debug/embed\"\n",
    "payload = {\n",
    "    \"text\": \"The transformer architecture allows for parallelization.\",\n",
    "    \"model_name\": \"bert\"\n",
    "}\n",
    "response = requests.post(url, json=payload)\n",
    "print(response.json()[\"dimension\"])"
   ],
   "id": "e9cb0c6c43239e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T13:04:23.341093400Z",
     "start_time": "2026-01-02T13:04:16.139348300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parse a PDF and get JSON\n",
    "url = \"http://localhost:8000/debug/parse-pdf\"\n",
    "files = {'file': open('./data/testPDFs/BERT.pdf', 'rb')}\n",
    "\n",
    "response = requests.post(url, files=files)\n",
    "data = response.json()\n",
    "\n",
    "print(\"Title detected:\", data['metadata_extracted']['title'])\n",
    "print(\"Sections found:\", list(data['sections'].keys()))"
   ],
   "id": "4dfdfe7a61d26fb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title detected: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n",
      "Sections found: ['Preamble', 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding', 'Abstract', '1 Introduction', '2 Related Work', '2.1 Unsupervised Feature-based Approaches', '2.2 Unsupervised Fine-tuning Approaches', '2.3 Transfer Learning from Supervised Data', '3 BERT', '3.1 Pre-training BERT', '3.2 Fine-tuning BERT', '4 Experiments', '4.1 GLUE', '4.2 SQuAD v1.1', '4.3 SQuAD v2.0', '4.4 SWAG', '5 Ablation Studies', '5.1 Effect of Pre-training Tasks', '5.2 Effect of Model Size', '5.3 Feature-based Approach with BERT', '6 Conclusion', 'References', \"Appendix for 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'\", 'A.1 Illustration of the Pre-training Tasks', 'A.2 Pre-training Procedure', 'A.3 Fine-tuning Procedure', 'A.4 Comparison of BERT, ELMo ,and OpenAI GPT', 'A.5 Illustrations of Fine-tuning on Different Tasks', 'B.1 Detailed Descriptions for the GLUE Benchmark Experiments.', 'C.1 Effect of Number of Training Steps', 'C.2 Ablation for Different Masking Procedures']\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T16:56:47.147406Z",
     "start_time": "2026-01-03T16:56:40.810835500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "url = \"http://localhost:8000/recommend\"\n",
    "\n",
    "# \"Attention Is All You Need\" (S2 ID) and \"BERT\" (ArXiv ID) as positive examples\n",
    "payload = {\n",
    "    \"positive_paper_ids\": [\n",
    "        \"649def34f8be52c8b66281af98ae884c09aef38b\",\n",
    "        \"arXiv:1810.04805\"\n",
    "    ],\n",
    "    \"negative_paper_ids\": [],\n",
    "    \"limit\": 5\n",
    "}\n",
    "\n",
    "try:\n",
    "    print(\"üß† Requesting recommendations...\")\n",
    "    response = requests.post(url, json=payload)\n",
    "    response.raise_for_status() # Raise error for 4xx/5xx\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    print(f\"\\n‚úÖ Received {len(data['recommendations'])} recommendations:\\n\")\n",
    "\n",
    "    for paper in data['recommendations']:\n",
    "        print(f\"üìÑ {paper['title']} ({paper['year']})\")\n",
    "        print(f\"   Authors: {', '.join([a['name'] for a in paper['authors']])}\")\n",
    "        print(f\"   Link: {paper['url']}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"‚ùå API Error: {e}\")\n",
    "    print(response.text)"
   ],
   "id": "b009b9bb2372a2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Requesting recommendations...\n",
      "\n",
      "‚úÖ Received 5 recommendations:\n",
      "\n",
      "üìÑ Mixed Information Bottleneck for Location Metonymy Resolution Using Pre-trained Language Models (2025)\n",
      "   Authors: Hao Wang, Tang Li, Siyuan Du, Xiao Wei\n",
      "   Link: https://www.semanticscholar.org/paper/843cedbf846f7f0e7ec7913d9ce422c381414551\n",
      "----------------------------------------\n",
      "üìÑ SciNER: Extracting Named Entities From ScientiÔ¨Åc Literature (cid:63) (None)\n",
      "   Authors: Zhi Hong, Roselyne Tchoua, Kyle Chard, Ian T. Foster\n",
      "   Link: https://www.semanticscholar.org/paper/5bc7d8dfad3f164cbc37fbf45b94b69b4154ae5d\n",
      "----------------------------------------\n",
      "üìÑ LIME: Making LLM Data More Efficient with Linguistic Metadata Embeddings (2025)\n",
      "   Authors: Sebastian Sztwiertnia, Felix Friedrich, K. Kersting, P. Schramowski, Bjorn Deiseroth\n",
      "   Link: https://www.semanticscholar.org/paper/275c9c93a9446df4c6231eec5f1bfb3429553d95\n",
      "----------------------------------------\n",
      "üìÑ ANAVIT: Enhancing Document-Level Relation Extraction with Anaphor Nodes and Visual Transformation (2025)\n",
      "   Authors: An Duc Vinh Pham, Quynh-Trang Pham Thi, T. Dang\n",
      "   Link: https://www.semanticscholar.org/paper/f1e010b4d01fe050b24a8a27bdb2b5ec76a08eef\n",
      "----------------------------------------\n",
      "üìÑ Advancing Text Summarization with Enhanced RoBERTa and Knowledge Graph Integration (2025)\n",
      "   Authors: R. Suganya\n",
      "   Link: https://www.semanticscholar.org/paper/22d693222cd0336e2d1480df00e7c4d8bd69f308\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T17:12:15.302267900Z",
     "start_time": "2026-01-03T17:12:11.835663100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "url = \"http://localhost:8000/paper/search\"\n",
    "title_query = \"Attention Is All You Need\"\n",
    "# Query parameters\n",
    "params = {\n",
    "    \"query\": title_query\n",
    "}\n",
    "\n",
    "try:\n",
    "    print(f\"üîé Searching for: '{title_query}'...\")\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    data = response.json()\n",
    "    paper_id = data.get(\"paperId\")\n",
    "\n",
    "    if paper_id:\n",
    "        print(f\"‚úÖ Found Paper ID: {paper_id}\")\n",
    "\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No paper found with that title.\")\n",
    "\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"‚ùå API Request Failed: {e}\")\n"
   ],
   "id": "d65d596a623ec40e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Searching for: 'Attention Is All You Need'...\n",
      "‚úÖ Found Paper ID: 204e3073870fae3d05bcbc2f6a8e263d9b72e776\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "75270a58f71db128"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
